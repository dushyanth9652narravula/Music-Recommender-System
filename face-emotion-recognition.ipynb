{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Dropout,Flatten\nfrom keras.optimizers import Adam \nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-07-12T08:26:41.631863Z","iopub.execute_input":"2023-07-12T08:26:41.632232Z","iopub.status.idle":"2023-07-12T08:26:41.637757Z","shell.execute_reply.started":"2023-07-12T08:26:41.632200Z","shell.execute_reply":"2023-07-12T08:26:41.636523Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Initializing image data generator with rescaling","metadata":{}},{"cell_type":"code","source":"train_data_gen = ImageDataGenerator(rescale = 1./255)\nvalidation_data_gen = ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T08:29:28.724413Z","iopub.execute_input":"2023-07-12T08:29:28.725484Z","iopub.status.idle":"2023-07-12T08:29:28.730122Z","shell.execute_reply.started":"2023-07-12T08:29:28.725449Z","shell.execute_reply":"2023-07-12T08:29:28.729144Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess all the train images","metadata":{}},{"cell_type":"code","source":"train_generator = train_data_gen.flow_from_directory(\n                                    \n                '/kaggle/input/fer2013/train',\n                target_size = (48,48),\n                batch_size = 64,\n                color_mode = \"grayscale\",\n                class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T08:33:34.274020Z","iopub.execute_input":"2023-07-12T08:33:34.274378Z","iopub.status.idle":"2023-07-12T08:33:43.291925Z","shell.execute_reply.started":"2023-07-12T08:33:34.274349Z","shell.execute_reply":"2023-07-12T08:33:43.290948Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 28709 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocess all the test images","metadata":{}},{"cell_type":"code","source":"validation_generator = validation_data_gen.flow_from_directory(\n    \n                '/kaggle/input/fer2013/test',\n                target_size = (48,48),\n                batch_size = 64,\n                color_mode = \"grayscale\",\n                class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T08:35:45.949999Z","iopub.execute_input":"2023-07-12T08:35:45.950408Z","iopub.status.idle":"2023-07-12T08:35:47.704031Z","shell.execute_reply.started":"2023-07-12T08:35:45.950375Z","shell.execute_reply":"2023-07-12T08:35:47.702951Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 7178 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Creating the Deep Learning Model","metadata":{}},{"cell_type":"code","source":"emotion_model = Sequential()\n\nemotion_model.add(Conv2D(32,kernel_size = (3,3),activation = 'relu',input_shape = (48,48,1)))\nemotion_model.add(Conv2D(64,kernel_size = (3,3),activation = 'relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2,2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Conv2D(128,kernel_size = (3,3),activation = 'relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2,2)))\nemotion_model.add(Conv2D(128,kernel_size = (3,3),activation = 'relu'))\nemotion_model.add(MaxPooling2D(pool_size = (2,2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Flatten())\nemotion_model.add(Dense(1024,activation = 'relu'))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(7,activation = 'softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-07-12T08:50:20.026917Z","iopub.execute_input":"2023-07-12T08:50:20.027352Z","iopub.status.idle":"2023-07-12T08:50:20.140646Z","shell.execute_reply.started":"2023-07-12T08:50:20.027318Z","shell.execute_reply":"2023-07-12T08:50:20.139674Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Compiling the Model","metadata":{}},{"cell_type":"code","source":"emotion_model.compile(loss = 'categorical_crossentropy',optimizer = Adam(lr = 0.0001,decay = 1e-6 ),metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-12T08:52:14.946219Z","iopub.execute_input":"2023-07-12T08:52:14.946635Z","iopub.status.idle":"2023-07-12T08:52:14.966845Z","shell.execute_reply.started":"2023-07-12T08:52:14.946584Z","shell.execute_reply":"2023-07-12T08:52:14.965893Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training the Model","metadata":{}},{"cell_type":"code","source":"emotion_model_info = emotion_model.fit_generator(\n    train_generator,\n    steps_per_epoch = 28709//64,\n    epochs = 100,\n    validation_data = validation_generator,\n    validation_steps = 7178//64,\n    initial_epoch = 50)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T09:30:37.522103Z","iopub.execute_input":"2023-07-12T09:30:37.522472Z","iopub.status.idle":"2023-07-12T10:01:40.758977Z","shell.execute_reply.started":"2023-07-12T09:30:37.522441Z","shell.execute_reply":"2023-07-12T10:01:40.757735Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 51/100\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_28/237661982.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  emotion_model_info = emotion_model.fit_generator(\n","output_type":"stream"},{"name":"stdout","text":"448/448 [==============================] - 33s 74ms/step - loss: 0.3577 - accuracy: 0.8710 - val_loss: 1.2398 - val_accuracy: 0.6246\nEpoch 52/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.3519 - accuracy: 0.8738 - val_loss: 1.2378 - val_accuracy: 0.6221\nEpoch 53/100\n448/448 [==============================] - 37s 83ms/step - loss: 0.3348 - accuracy: 0.8809 - val_loss: 1.2496 - val_accuracy: 0.6222\nEpoch 54/100\n448/448 [==============================] - 37s 82ms/step - loss: 0.3285 - accuracy: 0.8816 - val_loss: 1.2592 - val_accuracy: 0.6228\nEpoch 55/100\n448/448 [==============================] - 37s 82ms/step - loss: 0.3175 - accuracy: 0.8878 - val_loss: 1.2965 - val_accuracy: 0.6235\nEpoch 56/100\n448/448 [==============================] - 37s 83ms/step - loss: 0.3144 - accuracy: 0.8882 - val_loss: 1.2787 - val_accuracy: 0.6193\nEpoch 57/100\n448/448 [==============================] - 34s 77ms/step - loss: 0.3016 - accuracy: 0.8909 - val_loss: 1.2961 - val_accuracy: 0.6180\nEpoch 58/100\n448/448 [==============================] - 35s 78ms/step - loss: 0.2961 - accuracy: 0.8944 - val_loss: 1.3042 - val_accuracy: 0.6249\nEpoch 59/100\n448/448 [==============================] - 35s 77ms/step - loss: 0.2915 - accuracy: 0.8961 - val_loss: 1.3099 - val_accuracy: 0.6218\nEpoch 60/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.2776 - accuracy: 0.9011 - val_loss: 1.3435 - val_accuracy: 0.6222\nEpoch 61/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.2685 - accuracy: 0.9061 - val_loss: 1.3575 - val_accuracy: 0.6229\nEpoch 62/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.2697 - accuracy: 0.9017 - val_loss: 1.3323 - val_accuracy: 0.6223\nEpoch 63/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.2586 - accuracy: 0.9087 - val_loss: 1.3519 - val_accuracy: 0.6205\nEpoch 64/100\n448/448 [==============================] - 37s 82ms/step - loss: 0.2537 - accuracy: 0.9088 - val_loss: 1.3265 - val_accuracy: 0.6251\nEpoch 65/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.2497 - accuracy: 0.9134 - val_loss: 1.3723 - val_accuracy: 0.6204\nEpoch 66/100\n448/448 [==============================] - 35s 78ms/step - loss: 0.2394 - accuracy: 0.9161 - val_loss: 1.3876 - val_accuracy: 0.6221\nEpoch 67/100\n448/448 [==============================] - 34s 76ms/step - loss: 0.2432 - accuracy: 0.9135 - val_loss: 1.3330 - val_accuracy: 0.6247\nEpoch 68/100\n448/448 [==============================] - 34s 76ms/step - loss: 0.2334 - accuracy: 0.9177 - val_loss: 1.4001 - val_accuracy: 0.6208\nEpoch 69/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.2295 - accuracy: 0.9192 - val_loss: 1.3942 - val_accuracy: 0.6237\nEpoch 70/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.2221 - accuracy: 0.9217 - val_loss: 1.3888 - val_accuracy: 0.6251\nEpoch 71/100\n448/448 [==============================] - 34s 76ms/step - loss: 0.2172 - accuracy: 0.9239 - val_loss: 1.3936 - val_accuracy: 0.6254\nEpoch 72/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.2087 - accuracy: 0.9264 - val_loss: 1.4195 - val_accuracy: 0.6225\nEpoch 73/100\n448/448 [==============================] - 37s 83ms/step - loss: 0.2099 - accuracy: 0.9264 - val_loss: 1.4083 - val_accuracy: 0.6212\nEpoch 74/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.2089 - accuracy: 0.9277 - val_loss: 1.4126 - val_accuracy: 0.6200\nEpoch 75/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.2013 - accuracy: 0.9290 - val_loss: 1.4257 - val_accuracy: 0.6223\nEpoch 76/100\n448/448 [==============================] - 38s 85ms/step - loss: 0.1984 - accuracy: 0.9300 - val_loss: 1.4357 - val_accuracy: 0.6223\nEpoch 77/100\n448/448 [==============================] - 33s 74ms/step - loss: 0.1928 - accuracy: 0.9326 - val_loss: 1.4459 - val_accuracy: 0.6211\nEpoch 78/100\n448/448 [==============================] - 34s 77ms/step - loss: 0.1855 - accuracy: 0.9348 - val_loss: 1.4528 - val_accuracy: 0.6232\nEpoch 79/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.1845 - accuracy: 0.9347 - val_loss: 1.4729 - val_accuracy: 0.6218\nEpoch 80/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.1863 - accuracy: 0.9352 - val_loss: 1.4866 - val_accuracy: 0.6253\nEpoch 81/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.1845 - accuracy: 0.9342 - val_loss: 1.4527 - val_accuracy: 0.6228\nEpoch 82/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.1760 - accuracy: 0.9376 - val_loss: 1.4772 - val_accuracy: 0.6219\nEpoch 83/100\n448/448 [==============================] - 33s 72ms/step - loss: 0.1719 - accuracy: 0.9390 - val_loss: 1.4794 - val_accuracy: 0.6237\nEpoch 84/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.1756 - accuracy: 0.9386 - val_loss: 1.5163 - val_accuracy: 0.6217\nEpoch 85/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.1697 - accuracy: 0.9416 - val_loss: 1.4942 - val_accuracy: 0.6217\nEpoch 86/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.1663 - accuracy: 0.9429 - val_loss: 1.5655 - val_accuracy: 0.6222\nEpoch 87/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.1674 - accuracy: 0.9427 - val_loss: 1.4997 - val_accuracy: 0.6242\nEpoch 88/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.1632 - accuracy: 0.9424 - val_loss: 1.5324 - val_accuracy: 0.6249\nEpoch 89/100\n448/448 [==============================] - 37s 82ms/step - loss: 0.1588 - accuracy: 0.9445 - val_loss: 1.5602 - val_accuracy: 0.6212\nEpoch 90/100\n448/448 [==============================] - 35s 79ms/step - loss: 0.1623 - accuracy: 0.9435 - val_loss: 1.5491 - val_accuracy: 0.6218\nEpoch 91/100\n448/448 [==============================] - 34s 76ms/step - loss: 0.1584 - accuracy: 0.9434 - val_loss: 1.5482 - val_accuracy: 0.6242\nEpoch 92/100\n448/448 [==============================] - 35s 78ms/step - loss: 0.1557 - accuracy: 0.9463 - val_loss: 1.5437 - val_accuracy: 0.6217\nEpoch 93/100\n448/448 [==============================] - 38s 84ms/step - loss: 0.1543 - accuracy: 0.9454 - val_loss: 1.5391 - val_accuracy: 0.6169\nEpoch 94/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.1541 - accuracy: 0.9465 - val_loss: 1.5493 - val_accuracy: 0.6203\nEpoch 95/100\n448/448 [==============================] - 35s 78ms/step - loss: 0.1466 - accuracy: 0.9516 - val_loss: 1.5769 - val_accuracy: 0.6197\nEpoch 96/100\n448/448 [==============================] - 37s 83ms/step - loss: 0.1454 - accuracy: 0.9490 - val_loss: 1.5414 - val_accuracy: 0.6197\nEpoch 97/100\n448/448 [==============================] - 37s 82ms/step - loss: 0.1405 - accuracy: 0.9522 - val_loss: 1.5546 - val_accuracy: 0.6235\nEpoch 98/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.1460 - accuracy: 0.9495 - val_loss: 1.5704 - val_accuracy: 0.6243\nEpoch 99/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.1399 - accuracy: 0.9525 - val_loss: 1.5802 - val_accuracy: 0.6257\nEpoch 100/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.1421 - accuracy: 0.9498 - val_loss: 1.5778 - val_accuracy: 0.6242\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"model_json = emotion_model.to_json()\nwith open(\"emotion_model.json\", \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:09:13.888224Z","iopub.execute_input":"2023-07-12T10:09:13.888661Z","iopub.status.idle":"2023-07-12T10:09:13.896873Z","shell.execute_reply.started":"2023-07-12T10:09:13.888618Z","shell.execute_reply":"2023-07-12T10:09:13.895683Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# save trained model weight in .h5 file\nemotion_model.save_weights('emotion_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:09:27.540961Z","iopub.execute_input":"2023-07-12T10:09:27.541334Z","iopub.status.idle":"2023-07-12T10:09:27.593171Z","shell.execute_reply.started":"2023-07-12T10:09:27.541303Z","shell.execute_reply":"2023-07-12T10:09:27.592269Z"},"trusted":true},"execution_count":15,"outputs":[]}]}